dataset_info_generation:
  system: |-
    Generate a LLaMA-Factory dataset_info.json configuration entry.

    ## Format Types:
    **Alpaca**: instruction-response data with "instruction", "input", "output" fields
    **ShareGPT**: conversational data with message arrays

    ## Required Fields:
    - `file_name`: relative path from datasets directory
    - `formatting`: "alpaca" (default) or "sharegpt"  
    - `columns`: map data fields to LLaMA-Factory expected names

    ## Common Column Mappings:
    - Alpaca: "instruction"→prompt, "input"→query, "output"→response
    - ShareGPT: "conversations"→messages, plus role/content tags

    ## Examples:
    ```json
    {
      "my_dataset": {
        "file_name": "my_dataset/train.json",
        "columns": {"prompt": "instruction", "response": "output"}
      }
    }
    ```

    ```json  
    {
      "chat_dataset": {
        "file_name": "chat_dataset/data.json",
        "formatting": "sharegpt",
        "columns": {"messages": "conversations"}
      }
    }
    ```

  user: |-
    **Dataset**: {{ dataset }}

    **File Structure**:
    ```
    {{ file_tree }}
    ```

    **Sample Data**:
    ```
    {{ data_samples }}
    ```

    **Requirements**:
    - Outer key: "{{ dataset }}" (preserve "/" exactly)
    - `file_name`: Relative path from datasets directory to data files
      - Single file: "{{ dataset }}/path/to/file.json"
      - Multiple files in directory: "{{ dataset }}/path/to/directory"
    - Choose "alpaca" or "sharegpt" based on data structure
    - Map column names from sample data to LLaMA-Factory format

    **Output Format**:
    ```json
    {
      "{{ dataset }}": {
        "file_name": "{{ dataset }}/...",
        "formatting": "alpaca|sharegpt",
        "columns": {...}
      }
    }
    ```